{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6782c764-b84e-49e8-a242-639ff1275883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd \n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import skimage.io as io\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "from matplotlib.cm import viridis\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f983fa2-813e-49f9-987f-2c45b462f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datapath):\n",
    "    dataloader=DataLoader(Mydataset(datapath),batch_size=16,shuffle=True)\n",
    "    tensor_list_image=[]\n",
    "    tensor_list_mask_4d=[]\n",
    "    tensor_list_mask_3d=[]\n",
    "    for i,(image,mask_image,mask_output) in enumerate(dataloader):\n",
    "        tensor_list_mask_4d.append(mask_image)\n",
    "        tensor_list_image.append(image)\n",
    "        tensor_list_mask_3d.append(mask_output)\n",
    "    torch.save(tensor_list_mask_3d, 'groupproject/tensorlist/tensor_list_mask_3d.pt')\n",
    "    torch.save(tensor_list_mask_4d,  'groupproject/tensorlist/tensor_list_mask_4d.pt')\n",
    "    torch.save(tensor_list_image,  'groupproject/tensorlist/tensor_list_mask_image.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33012c-3ed6-4925-acc6-df26ed6f4730",
   "metadata": {},
   "source": [
    "Unet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6e0bbb-1a6f-4df4-8908-efc4ac89877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Conv, self).__init__()\n",
    "        self.layer=nn.Sequential(\n",
    "            nn.Conv2d(in_channel,out_channel,3,1,1,padding_mode='reflect',bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(out_channel,out_channel,3,1,1,padding_mode='reflect',bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.layer=nn.Sequential(\n",
    "            nn.Conv2d(channel,channel,3,2,1,padding_mode='reflect',bias=False),\n",
    "            nn.BatchNorm2d(channel),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.layer=nn.Conv2d(channel,channel//2,1,1)\n",
    "\n",
    "    def forward(self,x,feature):\n",
    "        up=F.interpolate(x,scale_factor=2,mode='nearest')\n",
    "        out= self.layer(up)\n",
    "        return torch.cat((out, feature),dim=1)\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet,self).__init__()\n",
    "        self.c1=Conv(3,64)\n",
    "        self.d1=DownSample(64)\n",
    "        self.c2=Conv(64,128)\n",
    "        self.d2=DownSample(128)\n",
    "        self.c3=Conv(128,256)\n",
    "        self.d3=DownSample(256)\n",
    "        self.c4=Conv(256,512)\n",
    "        self.d4=DownSample(512)\n",
    "        self.c5=Conv(512,1024)\n",
    "        self.u1=UpSample(1024)\n",
    "        self.c6=Conv(1024,512)\n",
    "        self.u2 = UpSample(512)\n",
    "        self.c7 = Conv(512, 256)\n",
    "        self.u3 = UpSample(256)\n",
    "        self.c8 = Conv(256, 128)\n",
    "        self.u4 = UpSample(128)\n",
    "        self.c9 = Conv(128, 64)\n",
    "        self.out=nn.Conv2d(64,4,3,1,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        R1=self.c1(x)\n",
    "        R2=self.c2(self.d1(R1))\n",
    "        R3 = self.c3(self.d2(R2))\n",
    "        R4 = self.c4(self.d3(R3))\n",
    "        R5 = self.c5(self.d4(R4))\n",
    "        O1=self.c6(self.u1(R5,R4))\n",
    "        O2 = self.c7(self.u2(O1, R3))\n",
    "        O3 = self.c8(self.u3(O2, R2))\n",
    "        O4 = self.c9(self.u4(O3, R1))\n",
    "\n",
    "        return self.out(O4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c2cf9-3482-4b8f-8ee3-ae9d0a67f557",
   "metadata": {},
   "source": [
    "musk images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83de0b8-7a98-43e4-98fc-0b95776089f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.35s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "with open('annotations.json', 'r', encoding='utf8') as file:\n",
    "    data = json.load(file)\n",
    "coco = COCO('annotations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249f3921-3de9-48f7-ab2a-68cebddeb6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dataprocessing(path):\n",
    "    files=os.listdir(path)\n",
    "    for file in files:\n",
    "        images=os.listdir(f'{path}'+'/'+f'{file}')\n",
    "        for image in images:\n",
    "            path_=(path+'/'+file+'./'+image)\n",
    "\n",
    "def musking(image_id):\n",
    "    image_path='/musks'\n",
    "    img = coco.imgs[image_id]\n",
    "    if not os.path.exists(f'masks/{img['identity']}/{img['file_name'][11:]}'):\n",
    "        image = np.array(Image.open(img['file_name']))\n",
    "        plt.imshow(image)\n",
    "        cat_ids = coco.getCatIds()\n",
    "        anns_ids = coco.getAnnIds(imgIds=img['id'], catIds=cat_ids, iscrowd=None)\n",
    "        anns = coco.loadAnns(anns_ids)\n",
    "        if anns!=[]:\n",
    "            category_colors = {1: viridis(0.1)[:3],\n",
    "                               2: viridis(0.5)[:3],\n",
    "                               3: viridis(0.9)[:3]}\n",
    "            colored_mask = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "            for ann in anns:\n",
    "                category_id = ann['category_id']\n",
    "                binary_mask = coco.annToMask(ann)\n",
    "                for i in range(3):\n",
    "                    colored_mask[:,:,i] += binary_mask * category_colors[category_id][i]\n",
    "            colored_mask = np.clip(colored_mask, 0, 1)\n",
    "            plt.imshow(colored_mask)\n",
    "            plt.axis('off')\n",
    "            if not os.path.exists('masks'):\n",
    "                os.makedirs('masks')\n",
    "            if not os.path.exists('masks/'+img['identity']):\n",
    "                os.makedirs('masks/'+img['identity'])\n",
    "            plt.savefig(f'masks/{img['identity']}/{img['file_name'][11:]}',bbox_inches='tight')\n",
    "        plt.clf()\n",
    "n=0\n",
    "for i in range(1,8730):\n",
    "    if n in [1000,2000,3000,4000,5000,6000,7000,8000]:\n",
    "        print(n)\n",
    "    musking(i)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f0d388-bd37-4d10-a303-57caacc39cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'images' \n",
    "mask_dir= 'masks'\n",
    "def delete_folders(main_dir):\n",
    "    for root, dirs, files in os.walk(main_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            shutil.move(file_path, os.path.join(main_dir, file))\n",
    "        for dir in list(dirs):\n",
    "            dir_path = os.path.join(root, dir)\n",
    "            if not os.listdir(dir_path): \n",
    "                os.rmdir(dir_path)\n",
    "delete_folders(image_dir)\n",
    "delete_folders(image_dir)\n",
    "delete_folders(mask_dir)\n",
    "delete_folders(mask_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a1dad-7d9e-4034-bb4f-e710d4e409e5",
   "metadata": {},
   "source": [
    "Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4681e06-4fbf-4fba-bc48-0f0fa035fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "class_color_dict={'turtle':(72,35,115),'flipers':(104,180,255),'head':(254,255,153)}\n",
    "def resize_(path,size=(256,256)):\n",
    "    image=Image.open(path)\n",
    "    temp=max(image.size)\n",
    "    mask=Image.new('RGB',(temp,temp),(0,0,0))\n",
    "    mask.paste(image)\n",
    "    mask=mask.resize(size)\n",
    "    return mask\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self,path):\n",
    "        self.path=path\n",
    "        self.name=[]\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for name in files:\n",
    "                self.name.append(os.path.join(root,name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        file_name=self.name[index]\n",
    "        mask_path=file_name\n",
    "        image_path=file_name.replace('masks','images')\n",
    "        mask_image=resize_(mask_path)\n",
    "        mask_output=mask_image\n",
    "        image=resize_(image_path)\n",
    "        mask_image=np.array(mask_image)\n",
    "        mask_image = mask_image[:, :, 0:1] \n",
    "        for x in range(256):\n",
    "            for y in range(256):\n",
    "                if np.array_equal(mask_image[x,y,:],[72]):\n",
    "                    mask_image[x,y,:]=np.array([0])\n",
    "                elif np.array_equal(mask_image[x,y,:],[104]):\n",
    "                    mask_image[x,y,:]=np.array([1])\n",
    "                elif np.array_equal(mask_image[x,y,:],[254]):\n",
    "                    mask_image[x,y,:]=np.array([2])\n",
    "                else:\n",
    "                    mask_image[x,y,:]=np.array([3])\n",
    "        image=transform(image)\n",
    "        mask_image= mask_image.transpose(2, 0, 1)\n",
    "        mask_image=np.squeeze(mask_image)\n",
    "        mask_image=torch.from_numpy(mask_image)\n",
    "        mask_output=transform(mask_output)\n",
    "        return image,mask_image,mask_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c86368-8637-4435-9c8c-d570c311b2b3",
   "metadata": {},
   "source": [
    "train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c340bd98-9349-4de9-9746-d405883ce41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def class_to_color(ndarray):\n",
    "    output=torch.randn(3,256,256)\n",
    "    for x in range(256):\n",
    "        for y in range(256):\n",
    "            max_axis = np.argmax(ndarray[:,x,y], axis=0)\n",
    "            if  max_axis==3:\n",
    "                output[:,x,y]=torch.tensor([0,0,0])\n",
    "            elif max_axis==0:\n",
    "                output[:,x,y]=torch.tensor([72,35,115])\n",
    "            elif max_axis==1:\n",
    "                output[:,x,y]=torch.tensor([104,180,255])\n",
    "            elif max_axis==2:\n",
    "                output[:,x,y]=torch.tensor([254,255,153])\n",
    "    return output\n",
    "\n",
    "image_dir = 'images'  \n",
    "mask_dir = 'masks'\n",
    "train_dir = 'train'\n",
    "val_dir = 'val'\n",
    "test_dir = 'test'\n",
    "for dir in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "train_images_dir = os.path.join( 'train','images')\n",
    "val_images_dir = os.path.join( 'val','images')\n",
    "test_images_dir = os.path.join('test','images')\n",
    "train_masks_dir = os.path.join( 'train','masks')\n",
    "val_masks_dir = os.path.join( 'val','masks')\n",
    "test_masks_dir = os.path.join('test','masks')\n",
    "for dir in [train_images_dir, val_images_dir, test_images_dir,train_masks_dir,val_masks_dir,test_masks_dir]:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "images = os.listdir(image_dir)\n",
    "masks = os.listdir(mask_dir)\n",
    "images = [img for img in images if img in masks]\n",
    "masks=list(masks)\n",
    "images.sort()\n",
    "masks.sort()\n",
    "data_pairs = list(zip(images, masks))\n",
    "random.shuffle(data_pairs)\n",
    "train_size = int(0.6 * len(masks))\n",
    "val_size = int(0.2 * len(masks))\n",
    "train_pairs = data_pairs[:train_size]\n",
    "val_pairs = data_pairs[train_size:train_size + val_size]\n",
    "test_pairs = data_pairs[train_size + val_size:]\n",
    "def copy_files(pairs, img_dir,mask_dir,img_dir_target,mask_dir_target):\n",
    "    for img,mask in pairs:\n",
    "        shutil.copy(os.path.join(img_dir, img), os.path.join(img_dir_target, img))\n",
    "        shutil.copy(os.path.join(mask_dir, mask), os.path.join(mask_dir_target, mask))\n",
    "copy_files(train_pairs,image_dir,mask_dir,train_images_dir, train_masks_dir)\n",
    "copy_files(val_pairs,image_dir,mask_dir,val_images_dir, val_masks_dir)\n",
    "copy_files(test_pairs,image_dir,mask_dir,test_images_dir, test_masks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a02104e1-6dba-4de6-a07a-0bbf4a2b0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsz\\AppData\\Local\\Temp\\ipykernel_19896\\1847690826.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(weight_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful load weight！\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[18], line 32\u001b[0m, in \u001b[0;36mMydataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m256\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m256\u001b[39m):\n\u001b[1;32m---> 32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m72\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     33\u001b[0m             mask_image[x,y,:]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(mask_image[x,y,:],[\u001b[38;5;241m104\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2439\u001b[0m, in \u001b[0;36marray_equal\u001b[1;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[0;32m   2437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal_nan:\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall())\n\u001b[0;32m   2440\u001b[0m \u001b[38;5;66;03m# Handling NaN values if equal_nan is True\u001b[39;00m\n\u001b[0;32m   2441\u001b[0m a1nan, a2nan \u001b[38;5;241m=\u001b[39m isnan(a1), isnan(a2)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "weight_path='weights/Unet.pth'\n",
    "datapath='train/masks'\n",
    "testpath='test/masks'\n",
    "save_path='evaluate'\n",
    "if not os.path.exists('evaluate'):\n",
    "    os.makedirs('evaluate')\n",
    "dataloader=DataLoader(Mydataset(datapath),batch_size=4,shuffle=True)\n",
    "net=Unet().to(device)\n",
    "net.train()\n",
    "if not os.path.exists('weights'):\n",
    "    os.makedirs('weights')\n",
    "if os.path.exists(weight_path):\n",
    "    net.load_state_dict(torch.load(weight_path))\n",
    "    print('successful load weight！')\n",
    "else:\n",
    "    print('not successful load weight')\n",
    "opt=optim.Adam(net.parameters(),lr=0.0001)\n",
    "weights=torch.tensor([12.9,61.48,74.07,1.0]).to(device)\n",
    "loss_fun=nn.CrossEntropyLoss(weight=weights)\n",
    "epoch=0\n",
    "while True:\n",
    "    for i,(image,mask_image,mask_output) in enumerate(dataloader):\n",
    "        image,mask_image,mask_output=image.to(device),mask_image.to(device),mask_output.to(device)\n",
    "        mask_image=mask_image.to(torch.long)\n",
    "        out=net(image)\n",
    "        train_loss=loss_fun(out,mask_image)\n",
    "        opt.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "        # print(out[0,:,128,128])\n",
    "        # print(mask_image[0,128,128])\n",
    "        if i%5==0:\n",
    "            print(f'epoch:{epoch}-{i},train_loss:{train_loss.item()}')\n",
    "        if i%50==0:\n",
    "            torch.save(net.state_dict(),weight_path)\n",
    "        if i%100==0:\n",
    "            _image=image[0]\n",
    "            _mask=mask_output[0]\n",
    "            _out=out[0]\n",
    "            output=_out.detach().cpu().numpy()\n",
    "            output=class_to_color(output)\n",
    "            output=output.to(device)\n",
    "            output=output/255\n",
    "            img=torch.stack([_image,_mask,output],dim=0)\n",
    "            save_image(img,os.path.join(save_path,str(i))+'.png')\n",
    "    epoch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31e8b418-6a5c-4885-ae44-2a25518e4d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsz\\AppData\\Local\\Temp\\ipykernel_19896\\2515309961.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(weight_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful load weight！\n",
      "epoch=0,average iou=0.24891281127929688,turtle_iou=0.0,flipers_iou=0.0,head_iou=0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m head_iou_history\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[18], line 34\u001b[0m, in \u001b[0;36mMydataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(mask_image[x,y,:],[\u001b[38;5;241m72\u001b[39m]):\n\u001b[0;32m     33\u001b[0m     mask_image[x,y,:]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m104\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     35\u001b[0m     mask_image[x,y,:]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(mask_image[x,y,:],[\u001b[38;5;241m254\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:2439\u001b[0m, in \u001b[0;36marray_equal\u001b[1;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[0;32m   2437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal_nan:\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall())\n\u001b[0;32m   2440\u001b[0m \u001b[38;5;66;03m# Handling NaN values if equal_nan is True\u001b[39;00m\n\u001b[0;32m   2441\u001b[0m a1nan, a2nan \u001b[38;5;241m=\u001b[39m isnan(a1), isnan(a2)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def plot_metrics(val_iou_history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # draw line chart\n",
    "    plt.plot(val_iou_history, label='Validation IoU')\n",
    "    plt.xlabel('test_sample')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Validation Iou')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def calculate_iou(predictions, labels, num_classes):\n",
    "    predicted_classes=predictions.squeeze(0)\n",
    "    labels=labels.squeeze(0)\n",
    "    ious = []\n",
    "    for class_id in range(num_classes):\n",
    "        intersection = ((predicted_classes == class_id) & (labels == class_id)).sum().item()\n",
    "        union = ((predicted_classes == class_id) | (labels == class_id)).sum().item()\n",
    "        if union == 0:\n",
    "            iou = 0 \n",
    "        else:\n",
    "            iou = intersection / union\n",
    "        ious.append(iou)\n",
    "    return ious\n",
    "\n",
    "testloader=DataLoader(Mydataset(testpath),batch_size=1,shuffle=True)\n",
    "if not os.path.exists('weights'):\n",
    "    os.makedirs('weights')\n",
    "if os.path.exists(weight_path):\n",
    "    net.load_state_dict(torch.load(weight_path))\n",
    "    print('successful load weight！')\n",
    "else:\n",
    "    print('not successful load weight')\n",
    "net.eval()\n",
    "iou_history=[]\n",
    "turtle_iou_history=[]\n",
    "flipers_iou_history=[]\n",
    "head_iou_history=[]\n",
    "with torch.no_grad():\n",
    "    for i,(image,mask_image,mask_output) in enumerate(testloader):\n",
    "        image=image.to(device)\n",
    "        mask_image=mask_image.to(device)\n",
    "        out=net(image)\n",
    "        prediction=torch.argmax(out,dim=1)\n",
    "        ious=calculate_iou(prediction,mask_image,4)\n",
    "        iou_history.append(np.mean(ious))\n",
    "        turtle_iou_history.append(ious[0])\n",
    "        flipers_iou_history.append(ious[1])\n",
    "        head_iou_history.append(ious[2])\n",
    "        if i%100==0:\n",
    "            print(f'epoch={i},average iou={np.mean(iou_history)},turtle_iou={np.mean(turtle_iou_history)},flipers_iou={np.mean(flipers_iou_history)},head_iou={np.mean(head_iou_history)}')\n",
    "    plot_metrics(iou_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a4443-1aab-4501-91fd-88645b13f158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
